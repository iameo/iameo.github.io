{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN. What NaN? Handling missing data. (Regression)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning algorithms work well depending on a number of factors; one being the quality of the presented data. In fact, preparing/preprocessing your data to make a magical input is somewhere in the critical zone on a Wizard's(here, Data Scientist) orb, and should, like other factors, be taken serious in preparing, before walking it into an ML vanishing cabinet.\n",
    "\n",
    "We will look at how to achieve quality data using some preprocessing techiques inorder to build a robust machine learning model, and we might be lucky enough to test it on real data.\n",
    "\n",
    "## workflow:\n",
    "- Identifying missing values or unknown values.\n",
    "- Removing/imputing missing values from the dataset\n",
    "- Getting categorical data to play nice with our ML model.\n",
    "- Drop this. Drop that. Selecting relevant features.\n",
    "\n",
    "Having one or more missing values(NaN - Not a Number) lurking around in a dataset is not something that should meet you in surprise, if any thing having not to see one in a big dataset should even scare you before hunting for the powerhouse behind such beauty disguised as a dataset. Why? Like every scientific data collecting there's prone to be an error; error in reading a value or just sheer abandoness, or leaving a particular field blank for a couple of reason. These empty fields are registed as either <code>NULL</code> or <code>NaN</code>.\n",
    "\n",
    "How would a couple of missing values or unknown values do us harm, you ask. \n",
    "\n",
    "Let's delve into some practical techniques for dealing with missing values by either removing these NaNs or imputing them.\n",
    "\n",
    "\n",
    "\n",
    "### Identifying missing values or unknown values.\n",
    "\n",
    "For the sake of this post I have prepared a sample data with some intentionally missing values so as to give us a somewhat personal look at this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary (NGN)</th>\n",
       "      <th>Level</th>\n",
       "      <th>Desk Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>89500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Salary (NGN)  Level  Desk Number\n",
       "0   22       89500.0      2         12.0\n",
       "1   19       95000.0      4          6.0\n",
       "2   32       40000.0      0          NaN\n",
       "3   25           NaN      1          3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #for reading data, making dataframes, csv file I/O\n",
    "\n",
    "df = pd.read_csv('~/datasets/dumdum/dummy_data.csv', sep=',') #import dummy data\n",
    "\n",
    "df #call data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             0\n",
       "Salary (NGN)    1\n",
       "Level           0\n",
       "Desk Number     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.isna().sum() #checking the number of NaN in each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we can see Age has no presence of NaN, Salary and Desk number have a value of 1. By looking at df you can point them out.\n",
    "\n",
    "Easy peasy lemon squeezy. Let's move on, shall we?\n",
    "\n",
    "\n",
    "## Removing/imputing missing values from the dataset.\n",
    "\n",
    "Simply removing missing values could be a fun task, albiet a problematic one. Inorder to do this one would have to decide on which to remove; columns(features) or rows(samples). And even then you'd still have to go through the judgemental feelings by the gods of data on why you would snap your fingers on some (potentially) good data.\n",
    "\n",
    "Again, it's a fun task. See how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary (NGN)</th>\n",
       "      <th>Level</th>\n",
       "      <th>Desk Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>89500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Salary (NGN)  Level  Desk Number\n",
       "0   22       89500.0      2         12.0\n",
       "1   19       95000.0      4          6.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0) #drop rows(axis = 0) that contain Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Level\n",
       "0   22      2\n",
       "1   19      4\n",
       "2   32      0\n",
       "3   25      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=1) #drop columns(axis=1) that contain Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy? yeah?\n",
    "\n",
    "__NB__: \n",
    "1. This method of dropping rows and columns could be detrimental in the long run as (valuable) samples/features could be eliminated, risking a reliable analysis.\n",
    "2. The dropna method is a fully equipped method. Do check around for other implementations, including dropping   specific rows that contain Nan, subsets and threshes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "\n",
    "This is the recommended approach when it's dealing with missing values. It entails replacing Nan with mean, median or mode of that particular row/column.\n",
    "A convenient way to achieve this is by using the <code>Imputer</code> class from __scikit-learn__, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.20000000e+01, 8.95000000e+04, 2.00000000e+00, 1.20000000e+01],\n",
       "       [1.90000000e+01, 9.50000000e+04, 4.00000000e+00, 6.00000000e+00],\n",
       "       [3.20000000e+01, 4.00000000e+04, 0.00000000e+00, 7.00000000e+00],\n",
       "       [2.50000000e+01, 7.48333333e+04, 1.00000000e+00, 3.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imput = Imputer(missing_values='NaN', strategy='mean', axis=0) #strategies = mean, median, most_frequent.\n",
    "imput = imput.fit(df.values) #fit the values.\n",
    "imputed_data = imput.transform(df.values) #then transforms it.\n",
    "imputed_data #show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   22, 89500,     2,    12],\n",
       "       [   19, 95000,     4,     6],\n",
       "       [   32, 40000,     0,     7],\n",
       "       [   25, 74833,     1,     3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.astype(int)  #so we can get a better visualization of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of a task, no? We imported the <code>Imputer</code> class from __scikit-learn__, gave it a strategy to handle the data, fitted the data and then transformed it. Easy peasy--no? Just go over it line by line.\n",
    "\n",
    "__NB__:\n",
    "- The axis here is quite different from the previous. Here 0 is for row while 1 is for column.\n",
    "- The strategy <code>most_frequent</code> is suitable for imputing categorical feature values, for example, a feature column that contains an encoding of color names, such as green, orange, and blue.\n",
    "- Understanding the scikit-learn estimator API:\n",
    "    (image)\n",
    "    \n",
    "- The <code>fit</code> method learns the parameter from the training data, and the <code>transform</code> method use these parameters to transform the data. \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
